{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvdhutBashte1605/PRODIGY_GA_04/blob/main/TASK4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIWE3PizaLM7",
        "outputId": "e8896366-41d3-4f8c-b471-a6ef1ae1ea64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt0pXc0Lawfx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4IXMoOPcW1E"
      },
      "outputs": [],
      "source": [
        "class UNetGenerator(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNetGenerator, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            self._block(in_channels, 64, 4, 2, 1),\n",
        "            self._block(64, 128, 4, 2, 1),\n",
        "            self._block(128, 256, 4, 2, 1),\n",
        "            self._block(256, 512, 4, 2, 1),\n",
        "            self._block(512, 512, 4, 2, 1),\n",
        "            self._block(512, 512, 4, 2, 1),\n",
        "            self._block(512, 512, 4, 2, 1),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            self._upblock(512, 512, 4, 2, 1),\n",
        "            self._upblock(1024, 512, 4, 2, 1),\n",
        "            self._upblock(1024, 512, 4, 2, 1),\n",
        "            self._upblock(1024, 256, 4, 2, 1),\n",
        "            self._upblock(512, 128, 4, 2, 1),\n",
        "            self._upblock(256, 64, 4, 2, 1),\n",
        "            nn.ConvTranspose2d(128, out_channels, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "    def _upblock(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder[0](x)\n",
        "        enc2 = self.encoder[1](enc1)\n",
        "        enc3 = self.encoder[2](enc2)\n",
        "        enc4 = self.encoder[3](enc3)\n",
        "        enc5 = self.encoder[4](enc4)\n",
        "        enc6 = self.encoder[5](enc5)\n",
        "        enc7 = self.encoder[6](enc6)\n",
        "        dec1 = self.decoder[0](enc7)\n",
        "        dec2 = self.decoder[1](torch.cat([dec1, enc6], dim=1))\n",
        "        dec3 = self.decoder[2](torch.cat([dec2, enc5], dim=1))\n",
        "        dec4 = self.decoder[3](torch.cat([dec3, enc4], dim=1))\n",
        "        dec5 = self.decoder[4](torch.cat([dec4, enc3], dim=1))\n",
        "        dec6 = self.decoder[5](torch.cat([dec5, enc2], dim=1))\n",
        "        dec7 = self.decoder[6](torch.cat([dec6, enc1], dim=1))\n",
        "        return self.decoder[7](dec7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT-lEMNDcikl"
      },
      "outputs": [],
      "source": [
        "class PatchGANDiscriminator(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(PatchGANDiscriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            self._block(in_channels * 2, 64, 4, 2, 1),\n",
        "            self._block(64, 128, 4, 2, 1),\n",
        "            self._block(128, 256, 4, 2, 1),\n",
        "            self._block(256, 512, 4, 1, 1),\n",
        "            nn.Conv2d(512, 1, 4, 1, 1)\n",
        "        )\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        return self.model(torch.cat([x, y], dim=1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iilAWFgwcnmt"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = sorted(os.listdir(root_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root_dir, self.image_paths[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        w, h = img.size\n",
        "        input_image = img.crop((0, 0, w // 2, h))\n",
        "        target_image = img.crop((w // 2, 0, w, h))\n",
        "        if self.transform:\n",
        "            input_image = self.transform(input_image)\n",
        "            target_image = self.transform(target_image)\n",
        "        return input_image, target_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s39fpw1cyCEe"
      },
      "outputs": [],
      "source": [
        "def train_pix2pix(dataloader, generator, discriminator, g_optimizer, d_optimizer, criterion_gan, criterion_l1, device, num_epochs=100):\n",
        "     # Create results directory if it does not exist\n",
        "    if not os.path.exists('results'):\n",
        "        os.makedirs('results')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (input_image, target_image) in enumerate(dataloader):\n",
        "            input_image, target_image = input_image.to(device), target_image.to(device)\n",
        "\n",
        "            # Train Discriminator\n",
        "            d_optimizer.zero_grad()\n",
        "            real_output = discriminator(input_image, target_image)\n",
        "            fake_image = generator(input_image)\n",
        "            fake_output = discriminator(input_image, fake_image.detach())\n",
        "            d_loss_real = criterion_gan(real_output, torch.ones_like(real_output))\n",
        "            d_loss_fake = criterion_gan(fake_output, torch.zeros_like(fake_output))\n",
        "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            # Train Generator\n",
        "            g_optimizer.zero_grad()\n",
        "            fake_output = discriminator(input_image, fake_image)\n",
        "            g_loss_gan = criterion_gan(fake_output, torch.ones_like(fake_output))\n",
        "            g_loss_l1 = criterion_l1(fake_image, target_image)\n",
        "            g_loss = g_loss_gan + 100 * g_loss_l1\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "            if i % 50 == 0:\n",
        "                print(f'Epoch [{epoch}/{num_epochs}], Step [{i}/{len(dataloader)}], d_loss: {d_loss.item()}, g_loss: {g_loss.item()}')\n",
        "\n",
        "        save_image(fake_image, f'results/fake_image_epoch_{epoch}.png')\n",
        "        save_image(target_image, f'results/real_image_epoch_{epoch}.png')\n",
        "        save_image(input_image, f'results/input_image_epoch_{epoch}.png')\n",
        "\n",
        "    torch.save(generator.state_dict(), 'generator.pth')\n",
        "    torch.save(discriminator.state_dict(), 'discriminator.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC99-M1ryJLi",
        "outputId": "a147005f-6474-4274-f9d5-c67e82edf483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:952: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv_transpose2d(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/200], Step [0/25], d_loss: 0.7063785791397095, g_loss: 86.5526351928711\n",
            "Epoch [1/200], Step [0/25], d_loss: 0.22985190153121948, g_loss: 48.869224548339844\n",
            "Epoch [2/200], Step [0/25], d_loss: 0.3069782257080078, g_loss: 38.6231689453125\n",
            "Epoch [3/200], Step [0/25], d_loss: 0.05645301938056946, g_loss: 44.893489837646484\n",
            "Epoch [4/200], Step [0/25], d_loss: 0.1416645348072052, g_loss: 37.333412170410156\n",
            "Epoch [5/200], Step [0/25], d_loss: 0.29096367955207825, g_loss: 36.02899932861328\n",
            "Epoch [6/200], Step [0/25], d_loss: 0.13830724358558655, g_loss: 39.27992248535156\n",
            "Epoch [7/200], Step [0/25], d_loss: 0.1458873450756073, g_loss: 37.067039489746094\n",
            "Epoch [8/200], Step [0/25], d_loss: 0.4076288342475891, g_loss: 35.10472869873047\n",
            "Epoch [9/200], Step [0/25], d_loss: 0.21816307306289673, g_loss: 33.92790985107422\n",
            "Epoch [10/200], Step [0/25], d_loss: 0.1434810906648636, g_loss: 35.14015579223633\n",
            "Epoch [11/200], Step [0/25], d_loss: 0.1918073445558548, g_loss: 35.85015869140625\n",
            "Epoch [12/200], Step [0/25], d_loss: 0.24992069602012634, g_loss: 32.897865295410156\n",
            "Epoch [13/200], Step [0/25], d_loss: 0.11191070079803467, g_loss: 31.953584671020508\n",
            "Epoch [14/200], Step [0/25], d_loss: 0.09057425707578659, g_loss: 34.0792350769043\n",
            "Epoch [15/200], Step [0/25], d_loss: 0.211253359913826, g_loss: 32.67476272583008\n",
            "Epoch [16/200], Step [0/25], d_loss: 0.8663539886474609, g_loss: 29.93556785583496\n",
            "Epoch [17/200], Step [0/25], d_loss: 0.49673497676849365, g_loss: 24.0135555267334\n",
            "Epoch [18/200], Step [0/25], d_loss: 0.4043320119380951, g_loss: 27.902639389038086\n",
            "Epoch [19/200], Step [0/25], d_loss: 0.19771036505699158, g_loss: 23.000810623168945\n",
            "Epoch [20/200], Step [0/25], d_loss: 0.24974267184734344, g_loss: 28.51485252380371\n",
            "Epoch [21/200], Step [0/25], d_loss: 0.2902362048625946, g_loss: 22.09467887878418\n",
            "Epoch [22/200], Step [0/25], d_loss: 0.6857588887214661, g_loss: 21.904157638549805\n",
            "Epoch [23/200], Step [0/25], d_loss: 0.5164629220962524, g_loss: 20.01409149169922\n",
            "Epoch [24/200], Step [0/25], d_loss: 0.19792306423187256, g_loss: 20.051654815673828\n",
            "Epoch [25/200], Step [0/25], d_loss: 0.41383662819862366, g_loss: 17.083593368530273\n",
            "Epoch [26/200], Step [0/25], d_loss: 0.3696276545524597, g_loss: 17.9456729888916\n",
            "Epoch [27/200], Step [0/25], d_loss: 0.45044124126434326, g_loss: 18.07952117919922\n",
            "Epoch [28/200], Step [0/25], d_loss: 0.49987509846687317, g_loss: 17.339570999145508\n",
            "Epoch [29/200], Step [0/25], d_loss: 0.40152159333229065, g_loss: 14.846302032470703\n",
            "Epoch [30/200], Step [0/25], d_loss: 0.38924095034599304, g_loss: 16.898771286010742\n",
            "Epoch [31/200], Step [0/25], d_loss: 0.5533815026283264, g_loss: 14.685575485229492\n",
            "Epoch [32/200], Step [0/25], d_loss: 0.25491195917129517, g_loss: 17.158021926879883\n",
            "Epoch [33/200], Step [0/25], d_loss: 0.15725825726985931, g_loss: 15.271032333374023\n",
            "Epoch [34/200], Step [0/25], d_loss: 0.20756548643112183, g_loss: 15.122872352600098\n",
            "Epoch [35/200], Step [0/25], d_loss: 1.7000186443328857, g_loss: 15.527792930603027\n",
            "Epoch [36/200], Step [0/25], d_loss: 0.5693313479423523, g_loss: 13.238057136535645\n",
            "Epoch [37/200], Step [0/25], d_loss: 0.7060134410858154, g_loss: 16.135440826416016\n",
            "Epoch [38/200], Step [0/25], d_loss: 0.22105485200881958, g_loss: 14.45854377746582\n",
            "Epoch [39/200], Step [0/25], d_loss: 0.0745004266500473, g_loss: 14.90020751953125\n",
            "Epoch [40/200], Step [0/25], d_loss: 0.6871612668037415, g_loss: 10.815911293029785\n",
            "Epoch [41/200], Step [0/25], d_loss: 0.5351362228393555, g_loss: 11.61522102355957\n",
            "Epoch [42/200], Step [0/25], d_loss: 0.21856728196144104, g_loss: 11.794817924499512\n",
            "Epoch [43/200], Step [0/25], d_loss: 0.3175307512283325, g_loss: 13.214527130126953\n",
            "Epoch [44/200], Step [0/25], d_loss: 0.13733144104480743, g_loss: 13.622875213623047\n",
            "Epoch [45/200], Step [0/25], d_loss: 0.26502224802970886, g_loss: 13.796571731567383\n",
            "Epoch [46/200], Step [0/25], d_loss: 0.643851101398468, g_loss: 10.950045585632324\n",
            "Epoch [47/200], Step [0/25], d_loss: 0.45990270376205444, g_loss: 9.543340682983398\n",
            "Epoch [48/200], Step [0/25], d_loss: 0.5705325603485107, g_loss: 12.03958511352539\n",
            "Epoch [49/200], Step [0/25], d_loss: 0.1596769392490387, g_loss: 12.808871269226074\n",
            "Epoch [50/200], Step [0/25], d_loss: 0.18828393518924713, g_loss: 14.169180870056152\n",
            "Epoch [51/200], Step [0/25], d_loss: 0.10638263821601868, g_loss: 13.478460311889648\n",
            "Epoch [52/200], Step [0/25], d_loss: 0.201992005109787, g_loss: 14.344307899475098\n",
            "Epoch [53/200], Step [0/25], d_loss: 0.508203387260437, g_loss: 10.996745109558105\n",
            "Epoch [54/200], Step [0/25], d_loss: 0.14577645063400269, g_loss: 12.809228897094727\n",
            "Epoch [55/200], Step [0/25], d_loss: 0.6422451734542847, g_loss: 9.736759185791016\n",
            "Epoch [56/200], Step [0/25], d_loss: 0.14198976755142212, g_loss: 14.73806095123291\n",
            "Epoch [57/200], Step [0/25], d_loss: 0.0850367397069931, g_loss: 11.582454681396484\n",
            "Epoch [58/200], Step [0/25], d_loss: 0.6686930656433105, g_loss: 9.960917472839355\n",
            "Epoch [59/200], Step [0/25], d_loss: 0.13043396174907684, g_loss: 12.161819458007812\n",
            "Epoch [60/200], Step [0/25], d_loss: 0.08195748925209045, g_loss: 11.356416702270508\n",
            "Epoch [61/200], Step [0/25], d_loss: 0.08179531991481781, g_loss: 12.192769050598145\n",
            "Epoch [62/200], Step [0/25], d_loss: 0.009424670599400997, g_loss: 12.502952575683594\n",
            "Epoch [63/200], Step [0/25], d_loss: 0.007018533069640398, g_loss: 13.07172966003418\n",
            "Epoch [64/200], Step [0/25], d_loss: 0.02356504090130329, g_loss: 11.8877592086792\n",
            "Epoch [65/200], Step [0/25], d_loss: 0.7096322178840637, g_loss: 7.872183799743652\n",
            "Epoch [66/200], Step [0/25], d_loss: 0.363844633102417, g_loss: 8.752873420715332\n",
            "Epoch [67/200], Step [0/25], d_loss: 0.5480067729949951, g_loss: 12.79172134399414\n",
            "Epoch [68/200], Step [0/25], d_loss: 0.9379291534423828, g_loss: 10.51702880859375\n",
            "Epoch [69/200], Step [0/25], d_loss: 0.033968254923820496, g_loss: 11.321560859680176\n",
            "Epoch [70/200], Step [0/25], d_loss: 0.01129283756017685, g_loss: 13.762031555175781\n",
            "Epoch [71/200], Step [0/25], d_loss: 0.02956092730164528, g_loss: 11.458565711975098\n",
            "Epoch [72/200], Step [0/25], d_loss: 0.020662885159254074, g_loss: 15.678860664367676\n",
            "Epoch [73/200], Step [0/25], d_loss: 0.0032208911143243313, g_loss: 12.649784088134766\n",
            "Epoch [74/200], Step [0/25], d_loss: 0.006115600932389498, g_loss: 12.451492309570312\n",
            "Epoch [75/200], Step [0/25], d_loss: 0.01043945923447609, g_loss: 11.222782135009766\n",
            "Epoch [76/200], Step [0/25], d_loss: 0.009788118302822113, g_loss: 15.20771598815918\n",
            "Epoch [77/200], Step [0/25], d_loss: 0.006282956805080175, g_loss: 13.363697052001953\n",
            "Epoch [78/200], Step [0/25], d_loss: 0.0035996551159769297, g_loss: 14.114011764526367\n",
            "Epoch [79/200], Step [0/25], d_loss: 0.0035859541967511177, g_loss: 13.28475570678711\n",
            "Epoch [80/200], Step [0/25], d_loss: 0.013286653906106949, g_loss: 14.49754524230957\n",
            "Epoch [81/200], Step [0/25], d_loss: 0.6973375678062439, g_loss: 6.740899085998535\n",
            "Epoch [82/200], Step [0/25], d_loss: 0.7135549783706665, g_loss: 6.174112319946289\n",
            "Epoch [83/200], Step [0/25], d_loss: 0.6554133892059326, g_loss: 6.188567161560059\n",
            "Epoch [84/200], Step [0/25], d_loss: 0.6619980335235596, g_loss: 6.098479747772217\n",
            "Epoch [85/200], Step [0/25], d_loss: 0.5918104648590088, g_loss: 6.677978992462158\n",
            "Epoch [86/200], Step [0/25], d_loss: 0.5209963917732239, g_loss: 6.916363716125488\n",
            "Epoch [87/200], Step [0/25], d_loss: 0.630835771560669, g_loss: 7.985755920410156\n",
            "Epoch [88/200], Step [0/25], d_loss: 0.573909342288971, g_loss: 7.012687683105469\n",
            "Epoch [89/200], Step [0/25], d_loss: 0.5584467649459839, g_loss: 6.781344890594482\n",
            "Epoch [90/200], Step [0/25], d_loss: 0.5130119323730469, g_loss: 7.052767753601074\n",
            "Epoch [91/200], Step [0/25], d_loss: 0.31161126494407654, g_loss: 7.940771579742432\n",
            "Epoch [92/200], Step [0/25], d_loss: 0.8887120485305786, g_loss: 7.641528129577637\n",
            "Epoch [93/200], Step [0/25], d_loss: 0.1889692097902298, g_loss: 8.390379905700684\n",
            "Epoch [94/200], Step [0/25], d_loss: 0.8147956728935242, g_loss: 7.280725479125977\n",
            "Epoch [95/200], Step [0/25], d_loss: 0.6044094562530518, g_loss: 6.765068531036377\n",
            "Epoch [96/200], Step [0/25], d_loss: 0.31333860754966736, g_loss: 7.440555572509766\n",
            "Epoch [97/200], Step [0/25], d_loss: 0.215901717543602, g_loss: 8.139094352722168\n",
            "Epoch [98/200], Step [0/25], d_loss: 0.04905811697244644, g_loss: 10.955246925354004\n",
            "Epoch [99/200], Step [0/25], d_loss: 0.024888336658477783, g_loss: 10.78805160522461\n",
            "Epoch [100/200], Step [0/25], d_loss: 0.022533679381012917, g_loss: 13.813774108886719\n",
            "Epoch [101/200], Step [0/25], d_loss: 0.0055585214868187904, g_loss: 12.655553817749023\n",
            "Epoch [102/200], Step [0/25], d_loss: 0.02065124735236168, g_loss: 12.85821533203125\n",
            "Epoch [103/200], Step [0/25], d_loss: 0.00826944038271904, g_loss: 11.321354866027832\n",
            "Epoch [104/200], Step [0/25], d_loss: 0.7359773516654968, g_loss: 6.497409343719482\n",
            "Epoch [105/200], Step [0/25], d_loss: 0.6568228006362915, g_loss: 5.7755231857299805\n",
            "Epoch [106/200], Step [0/25], d_loss: 0.6321367621421814, g_loss: 5.882722854614258\n",
            "Epoch [107/200], Step [0/25], d_loss: 0.4979705810546875, g_loss: 5.79825496673584\n",
            "Epoch [108/200], Step [0/25], d_loss: 0.515992283821106, g_loss: 7.183371067047119\n",
            "Epoch [109/200], Step [0/25], d_loss: 0.6509609818458557, g_loss: 5.754473686218262\n",
            "Epoch [110/200], Step [0/25], d_loss: 0.3294796049594879, g_loss: 7.68736457824707\n",
            "Epoch [111/200], Step [0/25], d_loss: 0.20857831835746765, g_loss: 8.92506217956543\n",
            "Epoch [112/200], Step [0/25], d_loss: 0.5698494911193848, g_loss: 8.05702018737793\n",
            "Epoch [113/200], Step [0/25], d_loss: 0.03848280385136604, g_loss: 10.234392166137695\n",
            "Epoch [114/200], Step [0/25], d_loss: 0.013279952108860016, g_loss: 11.710763931274414\n",
            "Epoch [115/200], Step [0/25], d_loss: 0.03749437257647514, g_loss: 10.25897216796875\n",
            "Epoch [116/200], Step [0/25], d_loss: 2.460942268371582, g_loss: 6.637892723083496\n",
            "Epoch [117/200], Step [0/25], d_loss: 0.6433809995651245, g_loss: 5.7445478439331055\n",
            "Epoch [118/200], Step [0/25], d_loss: 0.7807180285453796, g_loss: 10.191671371459961\n",
            "Epoch [119/200], Step [0/25], d_loss: 0.7845301032066345, g_loss: 6.675948143005371\n",
            "Epoch [120/200], Step [0/25], d_loss: 0.05441528186202049, g_loss: 9.60078239440918\n",
            "Epoch [121/200], Step [0/25], d_loss: 0.04267225041985512, g_loss: 8.983713150024414\n",
            "Epoch [122/200], Step [0/25], d_loss: 0.091379813849926, g_loss: 10.304105758666992\n",
            "Epoch [123/200], Step [0/25], d_loss: 0.014687673188745975, g_loss: 10.390947341918945\n",
            "Epoch [124/200], Step [0/25], d_loss: 0.8403332233428955, g_loss: 6.313266754150391\n",
            "Epoch [125/200], Step [0/25], d_loss: 0.2940358519554138, g_loss: 7.470719337463379\n",
            "Epoch [126/200], Step [0/25], d_loss: 0.09695353358983994, g_loss: 10.13984489440918\n",
            "Epoch [127/200], Step [0/25], d_loss: 0.6670793294906616, g_loss: 5.720515727996826\n",
            "Epoch [128/200], Step [0/25], d_loss: 0.024330368265509605, g_loss: 10.573005676269531\n",
            "Epoch [129/200], Step [0/25], d_loss: 0.006878088694065809, g_loss: 11.101459503173828\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Hyperparameters\n",
        "    in_channels = 3\n",
        "    out_channels = 3\n",
        "    lr = 0.0002\n",
        "    batch_size = 16\n",
        "    num_epochs = 200\n",
        "    image_size = 256\n",
        "\n",
        "    # Transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    # Dataset and DataLoader\n",
        "    dataset = ImageDataset(root_dir=\"/content/drive/MyDrive/facades/train\", transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Models\n",
        "    generator = UNetGenerator(in_channels, out_channels).to(device)\n",
        "    discriminator = PatchGANDiscriminator(in_channels).to(device)\n",
        "\n",
        "    # Optimizers\n",
        "    g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "    # Loss functions\n",
        "    criterion_gan = nn.BCEWithLogitsLoss()\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "\n",
        "    # Train the Pix2Pix model\n",
        "    train_pix2pix(dataloader, generator, discriminator, g_optimizer, d_optimizer, criterion_gan, criterion_l1, device, num_epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "\n",
        "# Load the generator\n",
        "generator = UNetGenerator(in_channels=3, out_channels=3)\n",
        "generator.load_state_dict(torch.load('generator.pth'))\n",
        "generator.eval()\n",
        "\n",
        "# Transform for input images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "def generate_image(input_image_path, output_image_path):\n",
        "    input_image = Image.open(input_image_path).convert(\"RGB\")\n",
        "    input_image = transform(input_image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake_image = generator(input_image)\n",
        "\n",
        "    save_image(fake_image, output_image_path)\n",
        "\n",
        "# Generate an image\n",
        "generate_image('/content/drive/MyDrive/content.jpg', '/content/drive/MyDrive/generated_image.png')\n"
      ],
      "metadata": {
        "id": "loLtd6C1wTju"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1UxK6S44bb-u8xWXAgS8clwQoqsnUjbfT",
      "authorship_tag": "ABX9TyPgBUO+69sTIOOp9cMr4KaI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}